(this.webpackJsonpportfolio=this.webpackJsonpportfolio||[]).push([[0],{11:function(e,t,s){"use strict";s.r(t);var n=s(1),i=s.n(n),o=s(3),c=s.n(o),r=(s(8),s(9),s(0));var a=function(){return Object(r.jsxs)(r.Fragment,{children:[Object(r.jsxs)("div",{className:"navContainer",id:"navBar",children:[Object(r.jsx)("a",{href:"#about",className:"navItem",children:Object(r.jsx)("h2",{children:"About"})}),Object(r.jsx)("a",{href:"#projects",className:"navItem",children:Object(r.jsx)("h2",{children:"Projects"})})]}),Object(r.jsxs)("div",{className:"contentWrapper",id:"contentWrap",children:[Object(r.jsxs)("div",{className:"contentContainer flex1",children:[Object(r.jsx)("span",{id:"about",className:"hidden-anchor"}),Object(r.jsx)("h1",{children:"About"}),Object(r.jsx)("div",{className:"scrollIntermediate",children:Object(r.jsxs)("div",{className:"contentItem",children:[Object(r.jsx)("img",{className:"headShot",src:"WFhs2.png",alt:"This is me"}),Object(r.jsxs)("div",{children:[Object(r.jsx)("h2",{children:"Carl Zettergren"}),Object(r.jsxs)("p",{children:["+46 76 112 32 33 ",Object(r.jsx)("br",{}),"carl.a.zettergren@gmail.com ",Object(r.jsx)("br",{}),"Stockholm"]}),Object(r.jsxs)("p",{children:["Last year of the Media Technology program at KTH, with a focus on visual media technology.",Object(r.jsx)("br",{})," ",Object(r.jsx)("br",{})," Writing my Degree Project in Computer Science and Engineering, specializing in Interactive Media Technology, at the Swedish National Forensic Centre (NFC) where I am investigating whether 360-degree video is suitable for use in emotionally preparatory scenario training for scenarios of undue influence.",Object(r.jsx)("br",{})," ",Object(r.jsx)("br",{})," Outgoing and kind.",Object(r.jsx)("br",{})," ",Object(r.jsx)("br",{})," Can pop industrial quantities of popcorn."]})]})]})})]}),Object(r.jsxs)("div",{className:"contentContainer flex3",children:[Object(r.jsx)("span",{id:"projects",className:"hidden-anchor"}),Object(r.jsx)("h1",{children:"Projects"}),Object(r.jsxs)("div",{className:"scrollIntermediate",children:[Object(r.jsxs)("div",{id:"synth",className:"contentItem videoItem",children:[Object(r.jsx)("div",{className:"flex3",children:Object(r.jsxs)("video",{controls:!0,children:[Object(r.jsx)("source",{src:"/Syntheseyeser_final.mp4",type:"video/mp4"}),"Your browser does not support the video tag."]})}),Object(r.jsx)("p",{className:"flex2",children:"The SynthesEyser is an exploration in multimodal interactions. The gaze and gesture based instrument uses a Tobii eye-tracker to understand where on the custom-built UI the player is looking, changing the pitch and amount of effect applied to the sound. The volume is controlled through gestures in front of a proximity sensor. All of which is controlled via a Bela micro-controller."})]}),Object(r.jsxs)("div",{id:"synth",className:"contentItem videoItem",children:[Object(r.jsx)("div",{className:"flex3",children:Object(r.jsxs)("video",{controls:!0,children:[Object(r.jsx)("source",{src:"/Syntheseyeser_final.mp4",type:"video/mp4"}),"Your browser does not support the video tag."]})}),Object(r.jsx)("p",{className:"flex2",children:"The SynthesEyser is an exploration in multimodal interactions. The gaze and gesture based instrument uses a Tobii eye-tracker to understand where on the custom-built UI the player is looking, changing the pitch and amount of effect applied to the sound. The volume is controlled through gestures in front of a proximity sensor. All of which is controlled via a Bela micro-controller."})]}),Object(r.jsxs)("div",{id:"synth",className:"contentItem videoItem",children:[Object(r.jsx)("div",{className:"flex3",children:Object(r.jsxs)("video",{controls:!0,children:[Object(r.jsx)("source",{src:"/Syntheseyeser_final.mp4",type:"video/mp4"}),"Your browser does not support the video tag."]})}),Object(r.jsx)("p",{className:"flex2",children:"The SynthesEyser is an exploration in multimodal interactions. The gaze and gesture based instrument uses a Tobii eye-tracker to understand where on the custom-built UI the player is looking, changing the pitch and amount of effect applied to the sound. The volume is controlled through gestures in front of a proximity sensor. All of which is controlled via a Bela micro-controller."})]})]})]})]})]})},l=function(e){e&&e instanceof Function&&s.e(3).then(s.bind(null,12)).then((function(t){var s=t.getCLS,n=t.getFID,i=t.getFCP,o=t.getLCP,c=t.getTTFB;s(e),n(e),i(e),o(e),c(e)}))};c.a.render(Object(r.jsx)(i.a.StrictMode,{children:Object(r.jsx)(a,{})}),document.getElementById("root")),l()},8:function(e,t,s){},9:function(e,t,s){}},[[11,1,2]]]);
//# sourceMappingURL=main.035d0c62.chunk.js.map